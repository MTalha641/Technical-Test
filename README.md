# Ghost Kitchen Management System

## ğŸ“Œ Project Overview
This project is a **Ghost Kitchen Management System** that integrates:
- **PostgreSQL** as the database
- **Node.js (Express.js)** for the backend API
- **React.js** for the frontend
- **Python ETL script** to fetch and load data
- **Docker** to containerize the database

## ğŸš€ Features
- Manage locations, brands, and delivery platforms
- Store brand availability across locations and platforms
- API to retrieve and add new location-brand-platform records
- Authentication for secured endpoints
- ETL pipeline to import city-based location data

---

## ğŸ› ï¸ Setup Instructions

### 1ï¸âƒ£ **Clone the Repository**
```bash
git clone <repository-url>
cd ghost-kitchen-management
```

### 2ï¸âƒ£ **Backend Setup**
#### ğŸ“‚ Navigate to the backend folder:
```bash
cd backend
```
#### ğŸ“¦ Install dependencies:
```bash
npm install
```
#### ğŸ”‘ Set up environment variables:
Create a `.env` file in the `backend/` directory and add:
```
POSTGRES_USER=admin
POSTGRES_PASSWORD=admin123
POSTGRES_DB=ghost_kitchen
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
DATA_URL=https://simplemaps.com/static/data/world-cities/basic/simplemaps_worldcities_basicv1.75.zip
JWT_SECRET=<your-secret-key>
```
#### ğŸ—ï¸ Run database migrations:
```bash
npm run migrate
```
#### ğŸŒ± Seed the database:
```bash
node 002_seed_data.js
```
#### â–¶ï¸ Start the backend server:
```bash
npm start
```
The backend will run on `http://localhost:5000/api`.

---

### 3ï¸âƒ£ **Frontend Setup**
#### ğŸ“‚ Navigate to the frontend folder:
```bash
cd ../frontend
```
#### ğŸ“¦ Install dependencies:
```bash
npm install
```
#### ğŸ”‘ Set up environment variables:
Create a `.env` file in `frontend/` and add:
```
VITE_API_BASE_URL=http://localhost:5000/api
```
#### â–¶ï¸ Start the frontend app:
```bash
npm run dev
```
The frontend will run on `http://localhost:5173`.

---

### 4ï¸âƒ£ **Run PostgreSQL using Docker**
#### ğŸ³ Make sure Docker Desktop is installed.
#### â–¶ï¸ Start the database using Docker Compose:
```bash
cd backend
docker-compose up -d
```
This will start a PostgreSQL instance with the required credentials.

To stop the container:
```bash
docker-compose down
```

---

### 5ï¸âƒ£ **Run the ETL Script (Python)**
#### ğŸ“‚ Navigate to the ETL folder:
```bash
cd backend/etl
```
#### ğŸ“¦ Install dependencies:
First, create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On macOS/Linux
venv\Scripts\activate  # On Windows
```
Then install dependencies:
```bash
pip install -r requirements.txt
```
#### â–¶ï¸ Run the ETL script:
```bash
python etl_script.py
```
This will fetch city data, transform it, and insert it into the `locations` table.

---

## ğŸ“¡ API Endpoints
### 1ï¸âƒ£ **Retrieve Location-Brand-Platform Data**
**GET `/api/location-brand-platforms`**
Returns a list of joined data (location, brand, platform, status, commission rate).

### 2ï¸âƒ£ **Add a New Location-Brand-Platform Entry**
**POST `/api/location-brand-platforms`**
Body:
```json
{
  "location_id": "uuid",
  "brand_id": "uuid",
  "platform_id": "uuid",
  "status": "active",
  "commission_rate": 15.5
}
```

ğŸ”’ **Authentication Required**

---

## âš¡ SQL Query Optimization
To get the count of `location_brand_platforms` entries for a specific `location_id` and date range:
```sql
SELECT COUNT(*) FROM location_brand_platforms
WHERE location_id = $1
AND created_at BETWEEN $2 AND $3;
```
### ğŸ”¹ Indexing for Large Datasets
- **Composite Index** on (`location_id`, `created_at`) for faster queries.
- **Partitioning** based on date ranges for efficient lookups.
- **Partial Index** if queries focus on `active` records.

---

## ğŸ“ Additional Notes
- Ensure **Docker Desktop is running** before using `docker-compose`.
- The `.env` files should not be committed to Git.
- Use **Postman** or **cURL** to test the API endpoints.
- Use **pgAdmin** or `psql` to verify database entries.

---

## ğŸ’¡ Contributors
- **Muhammad Talha** ğŸš€

---

### âœ… Project is now ready to run! ğŸ‰

